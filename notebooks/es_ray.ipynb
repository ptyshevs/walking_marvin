{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "env = gym.make('Marvin-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-05 12:12:57,363\tINFO resource_spec.py:205 -- Starting Ray with 3.96 GiB memory available for workers and up to 4.0 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '10.111.6.11',\n",
       " 'redis_address': '10.111.6.11:19862',\n",
       " 'object_store_address': '/tmp/ray/session_2019-10-05_12-12-57_360461_33223/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-10-05_12-12-57_360461_33223/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2019-10-05_12-12-57_360461_33223'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(memory=4 * 1024 * 1024 * 1024, object_store_memory=4 * 1024 * 1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, layer_sizes, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        self.weights = [np.zeros((m, n)) * 1e-3 for m, n in zip(layer_sizes[1:], layer_sizes)]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        out = X\n",
    "        for W in self.weights:\n",
    "            Z = out @ W.T\n",
    "            out = np.tanh(Z)\n",
    "        if out.shape[0] == 1 and len(out.shape) == 1:\n",
    "            return out.item()\n",
    "        return out\n",
    "\n",
    "    def set_weights(self, weights, copy=False):\n",
    "        if copy:\n",
    "            self.weights = [np.copy(l) for l in weights]\n",
    "        else:\n",
    "            self.weights = weights\n",
    "        \n",
    "    def get_weights(self, copy=False):\n",
    "        if copy:\n",
    "            return [np.copy(l) for l in self.weights]\n",
    "        return self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_like(weights, sigma=1, rs=None):\n",
    "    \"\"\"\n",
    "    Create a sample of the same shapes as the input\n",
    "    @param weights: list of np.arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    if rs is None:\n",
    "        rs = np.random\n",
    "    \n",
    "    return [rs.randn(*l.shape) * sigma for l in weights]\n",
    "\n",
    "\n",
    "def combine_weights(params, delta_params, sigma):\n",
    "    return [W + dW * sigma for W, dW in zip(params, delta_params)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, env):\n",
    "    \n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    i = 0\n",
    "    r_sum = 0\n",
    "    while not done and i < 1500:\n",
    "        action = model.predict(observation)\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        i += 1\n",
    "        r_sum += reward\n",
    "    return r_sum\n",
    "\n",
    "def update_params(params, population, rewards, lr=0.05, sigma=0.1):\n",
    "    \"\"\"\n",
    "    Inplace update of parameters\n",
    "    \"\"\"\n",
    "    n = len(population)\n",
    "    for i in range(len(params)):\n",
    "        W = params[i]\n",
    "        \n",
    "        dW_accum = np.zeros_like(W)\n",
    "        for candidate, reward in zip(population, rewards):\n",
    "            dW = candidate[i]\n",
    "            dW_accum += reward * dW\n",
    "        W_new = W + lr / (n * sigma) * dW_accum\n",
    "        params[i] = W_new\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote(num_cpus=0.12)\n",
    "class ESWorker:\n",
    "    def __init__(self, layer_sizes, init_seed, env_name, seed, sigma=.1):\n",
    "        self.model = NN(layer_sizes, init_seed)\n",
    "        self.env = gym.make(env_name)\n",
    "        self.rs = np.random.RandomState(seed=seed)\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    def evaluate(self):\n",
    "        \n",
    "        candidate = sample_like(self.model.weights, rs=self.rs)\n",
    "        self.model.set_weights(combine_weights(self.model.get_weights(), candidate, self.sigma))\n",
    "        reward = evaluate_model(self.model, self.env)\n",
    "        return reward\n",
    "    \n",
    "    def update(self, weights):\n",
    "        self.model.set_weights(weights, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_seeds = [seed for seed in range(4)]\n",
    "# w_rss = [np.random.RandomState(seed=seed) for seed in w_seeds]\n",
    "# workers = [ESWorker.remote([24, 24, 4], 0, 'Marvin-v0', seed) for seed in range(4)]  # actor handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rewards = [ray.get(w.evaluate.remote()) for w in workers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population = [sample_like(nn.get_weights(), rs=rs) for rs in w_rss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update_params(nn.get_weights(), population, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ESRaySolver:\n",
    "    def __init__(self, model, environment, population_size=30, max_episode_len=1500,\n",
    "                 lr=0.05, lr_decay=0.999, sigma=0.1, verbose=False):\n",
    "        self.model = model\n",
    "        self.env = environment\n",
    "        self.population_size = population_size\n",
    "        self.max_episode_len = max_episode_len\n",
    "        self.lr = lr\n",
    "        self.lr_decay = lr_decay\n",
    "        self.sigma = sigma\n",
    "        self.verbose = verbose\n",
    "        self.w_seeds = [seed for seed in range(population_size)]\n",
    "        self.w_rss = [np.random.RandomState(seed=seed) for seed in self.w_seeds]\n",
    "        self.workers = [ESWorker.remote([24, 24, 4], 0, 'Marvin-v0', seed) for seed in self.w_seeds]  # actor handles\n",
    "    \n",
    "    def solve(self, weights=None, fitness_fn=None, n_generations=100, seed=None):\n",
    "        \"\"\"\n",
    "        If weights is none, simple MLP is assumed, otherwise this should be the list of weights matrices from some model\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            weights = self.model.get_weights(copy=True)\n",
    "        if fitness_fn is None:\n",
    "            fitness_fn = evaluate_model\n",
    "\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        lr = self.lr\n",
    "\n",
    "\n",
    "        \n",
    "        for generation in range(n_generations):\n",
    "    \n",
    "            rewards = [ray.get(w.evaluate.remote()) for w in self.workers]\n",
    "            population = [sample_like(weights, rs=rs) for rs in self.w_rss]\n",
    "\n",
    "            rewards = np.array(rewards)\n",
    "            r_mean, r_std = rewards.mean(), rewards.std()\n",
    "            rewards = (rewards - r_mean) / r_std\n",
    "            \n",
    "            update_params(weights, population, rewards, lr=lr, sigma=self.sigma)\n",
    "            [ray.get(w.update.remote(weights)) for w in self.workers]\n",
    "        \n",
    "            lr = lr * self.lr_decay\n",
    "            if self.verbose and (generation % int(self.verbose) == 0):\n",
    "                print(f'[{generation}]: E[R]={r_mean:.4f}, std(R)={r_std:.4f} | lr={lr:.4f}')\n",
    "        return weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-05 12:12:59,357\tWARNING worker.py:1779 -- WARNING: 12 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:12:59,976\tWARNING worker.py:1779 -- WARNING: 13 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:12:59,976\tWARNING worker.py:1779 -- WARNING: 14 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:12:59,977\tWARNING worker.py:1779 -- WARNING: 15 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:00,228\tWARNING worker.py:1779 -- WARNING: 16 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:00,589\tWARNING worker.py:1779 -- WARNING: 17 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:00,793\tWARNING worker.py:1779 -- WARNING: 18 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:00,817\tWARNING worker.py:1779 -- WARNING: 19 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:00,917\tWARNING worker.py:1779 -- WARNING: 20 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:01,283\tWARNING worker.py:1779 -- WARNING: 21 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:01,427\tWARNING worker.py:1779 -- WARNING: 22 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:01,496\tWARNING worker.py:1779 -- WARNING: 23 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:01,623\tWARNING worker.py:1779 -- WARNING: 24 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:01,927\tWARNING worker.py:1779 -- WARNING: 25 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:02,016\tWARNING worker.py:1779 -- WARNING: 26 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:03,121\tWARNING worker.py:1779 -- WARNING: 27 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:03,380\tWARNING worker.py:1779 -- WARNING: 28 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:03,426\tWARNING worker.py:1779 -- WARNING: 29 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:03,438\tWARNING worker.py:1779 -- WARNING: 30 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:03,821\tWARNING worker.py:1779 -- WARNING: 31 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:04,158\tWARNING worker.py:1779 -- WARNING: 32 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n",
      "2019-10-05 12:13:04,279\tWARNING worker.py:1779 -- WARNING: 33 PYTHON workers have been started. This could be a result of using a large number of actors, or it could be a consequence of using nested tasks (see https://github.com/ray-project/ray/issues/3644) for some a discussion of workarounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: E[R]=-60.7821, std(R)=43.1073 | lr=0.0300\n",
      "[5]: E[R]=-73.4601, std(R)=32.7864 | lr=0.0298\n",
      "[10]: E[R]=-89.5098, std(R)=27.2669 | lr=0.0297\n",
      "[15]: E[R]=-55.4909, std(R)=30.7682 | lr=0.0295\n",
      "[20]: E[R]=-62.0867, std(R)=40.0604 | lr=0.0294\n",
      "[25]: E[R]=-63.9547, std(R)=29.4058 | lr=0.0292\n",
      "[30]: E[R]=-55.8368, std(R)=39.7465 | lr=0.0291\n",
      "[35]: E[R]=-60.8313, std(R)=28.1254 | lr=0.0289\n",
      "[40]: E[R]=-66.6107, std(R)=32.6568 | lr=0.0288\n",
      "[45]: E[R]=-50.5356, std(R)=35.3773 | lr=0.0287\n",
      "[50]: E[R]=-45.5580, std(R)=33.8322 | lr=0.0285\n",
      "[55]: E[R]=5.1548, std(R)=34.8148 | lr=0.0284\n",
      "[60]: E[R]=17.0382, std(R)=43.2496 | lr=0.0282\n",
      "[65]: E[R]=36.0285, std(R)=86.4609 | lr=0.0281\n",
      "[70]: E[R]=46.2152, std(R)=78.4589 | lr=0.0279\n",
      "[75]: E[R]=38.1711, std(R)=56.1707 | lr=0.0278\n",
      "[80]: E[R]=33.0489, std(R)=77.1984 | lr=0.0277\n",
      "[85]: E[R]=69.8223, std(R)=59.1796 | lr=0.0275\n",
      "[90]: E[R]=73.9432, std(R)=72.0845 | lr=0.0274\n",
      "[95]: E[R]=93.9002, std(R)=65.1340 | lr=0.0273\n",
      "[100]: E[R]=80.3982, std(R)=49.4834 | lr=0.0271\n",
      "[105]: E[R]=85.8702, std(R)=45.4733 | lr=0.0270\n",
      "[110]: E[R]=55.9098, std(R)=81.3399 | lr=0.0268\n",
      "[115]: E[R]=65.4296, std(R)=79.0416 | lr=0.0267\n",
      "[120]: E[R]=77.7550, std(R)=58.9606 | lr=0.0266\n",
      "[125]: E[R]=78.5605, std(R)=61.5287 | lr=0.0264\n",
      "[130]: E[R]=143.4131, std(R)=66.1469 | lr=0.0263\n",
      "[135]: E[R]=102.3134, std(R)=115.6216 | lr=0.0262\n",
      "[140]: E[R]=153.7985, std(R)=94.3350 | lr=0.0261\n",
      "[145]: E[R]=132.0404, std(R)=58.2032 | lr=0.0259\n",
      "[150]: E[R]=180.6049, std(R)=100.3977 | lr=0.0258\n",
      "[155]: E[R]=169.6503, std(R)=69.4505 | lr=0.0257\n",
      "[160]: E[R]=209.9066, std(R)=92.9017 | lr=0.0255\n",
      "[165]: E[R]=191.7812, std(R)=112.2800 | lr=0.0254\n",
      "[170]: E[R]=214.6188, std(R)=67.9285 | lr=0.0253\n",
      "[175]: E[R]=207.4964, std(R)=91.3202 | lr=0.0252\n",
      "[180]: E[R]=173.8055, std(R)=120.8422 | lr=0.0250\n",
      "[185]: E[R]=181.9988, std(R)=123.1514 | lr=0.0249\n",
      "[190]: E[R]=217.2436, std(R)=101.2341 | lr=0.0248\n",
      "[195]: E[R]=225.1316, std(R)=70.9862 | lr=0.0247\n",
      "[200]: E[R]=241.4980, std(R)=17.5525 | lr=0.0245\n",
      "[205]: E[R]=225.1305, std(R)=26.5362 | lr=0.0244\n",
      "[210]: E[R]=214.0049, std(R)=92.6305 | lr=0.0243\n",
      "[215]: E[R]=234.8384, std(R)=34.0821 | lr=0.0242\n",
      "[220]: E[R]=227.3177, std(R)=94.6326 | lr=0.0240\n",
      "[225]: E[R]=224.4519, std(R)=41.1482 | lr=0.0239\n",
      "[230]: E[R]=217.1310, std(R)=43.3170 | lr=0.0238\n",
      "[235]: E[R]=242.6328, std(R)=12.5950 | lr=0.0237\n",
      "[240]: E[R]=233.7455, std(R)=32.3233 | lr=0.0236\n",
      "[245]: E[R]=235.4020, std(R)=48.0263 | lr=0.0235\n",
      "[250]: E[R]=225.0998, std(R)=57.9059 | lr=0.0233\n",
      "[255]: E[R]=241.0025, std(R)=45.5700 | lr=0.0232\n",
      "[260]: E[R]=230.0463, std(R)=67.1193 | lr=0.0231\n",
      "[265]: E[R]=219.9114, std(R)=92.2269 | lr=0.0230\n",
      "[270]: E[R]=243.5771, std(R)=12.2499 | lr=0.0229\n",
      "[275]: E[R]=235.9521, std(R)=34.0707 | lr=0.0228\n",
      "[280]: E[R]=233.5123, std(R)=24.6423 | lr=0.0226\n",
      "[285]: E[R]=236.1482, std(R)=64.9061 | lr=0.0225\n",
      "[290]: E[R]=241.9555, std(R)=33.5321 | lr=0.0224\n",
      "[295]: E[R]=246.6880, std(R)=6.5501 | lr=0.0223\n"
     ]
    }
   ],
   "source": [
    "nn = NN([24, 24, 4], 0)\n",
    "es = ESRaySolver(nn, env, population_size=30, lr=0.03, verbose=5)\n",
    "weights = es.solve(n_generations=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pcl\n",
    "with open(\"ray_weights.pcl\", 'wb') as f:\n",
    "    pcl.dump(weights, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
