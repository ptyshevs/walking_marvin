{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "env = gym.make('Marvin-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self, layer_sizes, seed=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        self.weights = [np.zeros((m, n)) * 1e-3 for m, n in zip(layer_sizes[1:], layer_sizes)]\n",
    "    \n",
    "    def predict(self, X):\n",
    "        out = X\n",
    "        for W in self.weights:\n",
    "            Z = out @ W.T\n",
    "            out = np.tanh(Z)\n",
    "        if out.shape[0] == 1 and len(out.shape) == 1:\n",
    "            return out.item()\n",
    "        return out\n",
    "\n",
    "    def set_weights(self, weights, copy=False):\n",
    "        if copy:\n",
    "            self.weights = [np.copy(l) for l in weights]\n",
    "        else:\n",
    "            self.weights = weights\n",
    "        \n",
    "    def get_weights(self, copy=False):\n",
    "        if copy:\n",
    "            return [np.copy(l) for l in self.weights]\n",
    "        return self.weights\n",
    "    \n",
    "    def sample_like(self, sigma=1.0):\n",
    "        return [np.random.randn(*l.shape) * sigma for l in self.weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_like(weights, sigma=1):\n",
    "    \"\"\"\n",
    "    Create a sample of the same shapes as the input\n",
    "    @param weights: list of np.arrays\n",
    "    \"\"\"\n",
    "    return [np.random.randn(*l.shape) * sigma for l in weights]\n",
    "\n",
    "def combine_weights(params, delta_params, sigma):\n",
    "    return [W + dW * sigma for W, dW in zip(params, delta_params)]\n",
    "\n",
    "\n",
    "    \n",
    "def update_params(params, population, rewards, lr=0.05, sigma=0.1):\n",
    "    \"\"\"\n",
    "    Inplace update of parameters\n",
    "    \"\"\"\n",
    "    n = len(population)\n",
    "    for i in range(len(params)):\n",
    "        W = params[i]\n",
    "        dW_accum = np.zeros_like(W)\n",
    "\n",
    "        for candidate, reward in zip(population, rewards):\n",
    "            dW = candidate[i]\n",
    "            dW_accum += reward * dW\n",
    "\n",
    "        W_new = W + lr / (n * sigma) * dW_accum\n",
    "        params[i] = W_new\n",
    "\n",
    "    return params\n",
    "\n",
    "class ESSolver:\n",
    "    def __init__(self, model, environment, population_size=30, max_episode_len=1500,\n",
    "                 lr=0.05, lr_decay=0.999, sigma=0.1, verbose=False):\n",
    "        self.model = model\n",
    "        self.env = environment\n",
    "        self.population_size = population_size\n",
    "        self.max_episode_len = max_episode_len\n",
    "        self.lr = lr\n",
    "        self.lr_decay = lr_decay\n",
    "        self.sigma = sigma\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def solve(self, weights=None, fitness_fn=None, n_generations=100, seed=None):\n",
    "        \"\"\"\n",
    "        If weights is none, simple MLP is assumed, otherwise this should be the list of weights matrices from some model\n",
    "        \"\"\"\n",
    "        if weights is None:\n",
    "            weights = self.model.get_weights(copy=True)\n",
    "        if fitness_fn is None:\n",
    "            fitness_fn = self.evaluate_model\n",
    "\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        lr = self.lr\n",
    "        for generation in range(n_generations):\n",
    "    \n",
    "            population = []\n",
    "            rewards = []\n",
    "            \n",
    "            for i in range(self.population_size):\n",
    "                candidate = sample_like(weights)\n",
    "                \n",
    "                weights_combined = combine_weights(weights, candidate, sigma=self.sigma)\n",
    "                reward = fitness_fn(weights_combined)\n",
    "                \n",
    "                population.append(candidate)\n",
    "                rewards.append(reward)\n",
    "            \n",
    "            rewards = np.array(rewards)\n",
    "            r_mean, r_std = rewards.mean(), rewards.std()\n",
    "            rewards = (rewards - r_mean) / r_std\n",
    "            \n",
    "            update_params(weights, population, rewards, lr=lr, sigma=self.sigma)\n",
    "        \n",
    "        \n",
    "            lr = lr * self.lr_decay\n",
    "            if self.verbose and (generation % int(self.verbose) == 0):\n",
    "                print(f'[{generation}]: E[R]={r_mean:.4f}, std(R)={r_std:.4f} | lr={lr:.4f}')\n",
    "        return weights\n",
    "    \n",
    "    \n",
    "    def evaluate_model(self, weights):\n",
    "        self.model.set_weights(weights)\n",
    "        \n",
    "        observation = self.env.reset()\n",
    "        done = False\n",
    "        i = 0\n",
    "        r_sum = 0\n",
    "        while not done and i < self.max_episode_len:\n",
    "            action = self.model.predict(observation)\n",
    "            observation, reward, done, _ = self.env.step(action)\n",
    "            i += 1\n",
    "            r_sum += reward\n",
    "        return r_sum\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "nn = NN([24, 24, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]: E[R]=-74.2073, std(R)=43.1700 | lr=0.0500\n",
      "[1]: E[R]=-80.1933, std(R)=35.8936 | lr=0.0499\n",
      "[2]: E[R]=-93.6548, std(R)=35.8769 | lr=0.0499\n",
      "[3]: E[R]=-81.3174, std(R)=30.9690 | lr=0.0498\n",
      "[4]: E[R]=-85.9987, std(R)=35.1726 | lr=0.0498\n",
      "[5]: E[R]=-89.1679, std(R)=22.2086 | lr=0.0497\n",
      "[6]: E[R]=-92.6968, std(R)=26.8650 | lr=0.0497\n",
      "[7]: E[R]=-90.7875, std(R)=19.7223 | lr=0.0496\n",
      "[8]: E[R]=-104.0238, std(R)=19.3702 | lr=0.0496\n",
      "[9]: E[R]=-97.6063, std(R)=14.8156 | lr=0.0495\n",
      "[10]: E[R]=-87.3863, std(R)=19.1236 | lr=0.0495\n",
      "[11]: E[R]=-95.6501, std(R)=26.6276 | lr=0.0494\n",
      "[12]: E[R]=-89.3087, std(R)=22.7270 | lr=0.0494\n",
      "[13]: E[R]=-86.8189, std(R)=27.6159 | lr=0.0493\n",
      "[14]: E[R]=-92.9829, std(R)=22.6269 | lr=0.0493\n",
      "[15]: E[R]=-84.1191, std(R)=19.5775 | lr=0.0492\n",
      "[16]: E[R]=-87.1310, std(R)=32.4409 | lr=0.0492\n",
      "[17]: E[R]=-96.0725, std(R)=15.5007 | lr=0.0491\n",
      "[18]: E[R]=-99.8766, std(R)=26.8499 | lr=0.0491\n",
      "[19]: E[R]=-81.8875, std(R)=26.7100 | lr=0.0490\n",
      "[20]: E[R]=-80.7249, std(R)=26.3051 | lr=0.0490\n",
      "[21]: E[R]=-74.5017, std(R)=31.1832 | lr=0.0489\n",
      "[22]: E[R]=-87.8282, std(R)=21.8564 | lr=0.0489\n",
      "[23]: E[R]=-107.1111, std(R)=31.5500 | lr=0.0488\n",
      "[24]: E[R]=-86.6123, std(R)=20.1752 | lr=0.0488\n",
      "[25]: E[R]=-84.1996, std(R)=21.5200 | lr=0.0487\n",
      "[26]: E[R]=-111.5265, std(R)=37.2213 | lr=0.0487\n",
      "[27]: E[R]=-105.6456, std(R)=17.7312 | lr=0.0486\n",
      "[28]: E[R]=-107.7431, std(R)=25.2440 | lr=0.0486\n",
      "[29]: E[R]=-93.7883, std(R)=18.3692 | lr=0.0485\n",
      "[30]: E[R]=-93.4173, std(R)=25.9386 | lr=0.0485\n",
      "[31]: E[R]=-74.5788, std(R)=25.5565 | lr=0.0484\n",
      "[32]: E[R]=-87.1193, std(R)=35.2661 | lr=0.0484\n",
      "[33]: E[R]=-80.9308, std(R)=40.9544 | lr=0.0483\n",
      "[34]: E[R]=-79.2488, std(R)=24.5327 | lr=0.0483\n",
      "[35]: E[R]=-76.1908, std(R)=30.2201 | lr=0.0482\n",
      "[36]: E[R]=-68.5201, std(R)=25.5693 | lr=0.0482\n",
      "[37]: E[R]=-92.8693, std(R)=35.0303 | lr=0.0481\n",
      "[38]: E[R]=-45.3120, std(R)=33.4273 | lr=0.0481\n",
      "[39]: E[R]=-67.3698, std(R)=52.5999 | lr=0.0480\n",
      "[40]: E[R]=-94.1345, std(R)=43.3249 | lr=0.0480\n",
      "[41]: E[R]=-56.8857, std(R)=54.9616 | lr=0.0479\n",
      "[42]: E[R]=-68.8096, std(R)=44.3858 | lr=0.0479\n",
      "[43]: E[R]=-62.1784, std(R)=45.8644 | lr=0.0478\n",
      "[44]: E[R]=-63.8543, std(R)=36.5012 | lr=0.0478\n",
      "[45]: E[R]=-64.9234, std(R)=43.6943 | lr=0.0478\n",
      "[46]: E[R]=-91.8217, std(R)=55.8559 | lr=0.0477\n",
      "[47]: E[R]=-55.1212, std(R)=38.7737 | lr=0.0477\n",
      "[48]: E[R]=-43.2876, std(R)=50.4214 | lr=0.0476\n",
      "[49]: E[R]=-50.1524, std(R)=40.6272 | lr=0.0476\n",
      "[50]: E[R]=-71.4029, std(R)=61.4772 | lr=0.0475\n",
      "[51]: E[R]=-49.2443, std(R)=43.6499 | lr=0.0475\n",
      "[52]: E[R]=-28.3432, std(R)=41.3177 | lr=0.0474\n",
      "[53]: E[R]=-46.8812, std(R)=62.3127 | lr=0.0474\n",
      "[54]: E[R]=-37.0979, std(R)=58.2327 | lr=0.0473\n",
      "[55]: E[R]=-44.6367, std(R)=34.4290 | lr=0.0473\n",
      "[56]: E[R]=-38.2682, std(R)=66.4450 | lr=0.0472\n",
      "[57]: E[R]=-27.5799, std(R)=60.2614 | lr=0.0472\n",
      "[58]: E[R]=-6.6769, std(R)=64.2191 | lr=0.0471\n",
      "[59]: E[R]=-16.3467, std(R)=44.2804 | lr=0.0471\n",
      "[60]: E[R]=-5.2351, std(R)=44.4439 | lr=0.0470\n",
      "[61]: E[R]=5.0635, std(R)=29.1033 | lr=0.0470\n",
      "[62]: E[R]=-23.8751, std(R)=49.7273 | lr=0.0469\n",
      "[63]: E[R]=-9.7665, std(R)=60.7344 | lr=0.0469\n",
      "[64]: E[R]=-9.0548, std(R)=54.5368 | lr=0.0469\n",
      "[65]: E[R]=-1.4808, std(R)=54.7962 | lr=0.0468\n",
      "[66]: E[R]=4.8978, std(R)=59.2181 | lr=0.0468\n",
      "[67]: E[R]=31.3837, std(R)=60.7536 | lr=0.0467\n",
      "[68]: E[R]=38.7639, std(R)=49.6555 | lr=0.0467\n",
      "[69]: E[R]=47.3884, std(R)=49.8940 | lr=0.0466\n",
      "[70]: E[R]=71.1260, std(R)=75.4231 | lr=0.0466\n",
      "[71]: E[R]=41.7478, std(R)=107.2500 | lr=0.0465\n",
      "[72]: E[R]=79.3172, std(R)=63.0507 | lr=0.0465\n",
      "[73]: E[R]=14.7713, std(R)=109.9960 | lr=0.0464\n",
      "[74]: E[R]=69.8895, std(R)=88.2180 | lr=0.0464\n",
      "[75]: E[R]=64.3747, std(R)=53.1570 | lr=0.0463\n",
      "[76]: E[R]=-12.2460, std(R)=129.9328 | lr=0.0463\n",
      "[77]: E[R]=-14.3661, std(R)=93.7214 | lr=0.0462\n",
      "[78]: E[R]=-20.6458, std(R)=100.5188 | lr=0.0462\n",
      "[79]: E[R]=12.1862, std(R)=77.1431 | lr=0.0462\n",
      "[80]: E[R]=78.9999, std(R)=75.2706 | lr=0.0461\n",
      "[81]: E[R]=15.7657, std(R)=83.3764 | lr=0.0461\n",
      "[82]: E[R]=37.1789, std(R)=116.7566 | lr=0.0460\n",
      "[83]: E[R]=100.7795, std(R)=60.8813 | lr=0.0460\n",
      "[84]: E[R]=103.7072, std(R)=103.4322 | lr=0.0459\n",
      "[85]: E[R]=50.7845, std(R)=106.2179 | lr=0.0459\n",
      "[86]: E[R]=-45.6768, std(R)=101.6602 | lr=0.0458\n",
      "[87]: E[R]=98.6521, std(R)=88.1735 | lr=0.0458\n",
      "[88]: E[R]=103.6400, std(R)=104.1415 | lr=0.0457\n",
      "[89]: E[R]=133.4823, std(R)=55.4324 | lr=0.0457\n",
      "[90]: E[R]=104.4814, std(R)=60.7722 | lr=0.0456\n",
      "[91]: E[R]=86.9628, std(R)=93.0293 | lr=0.0456\n",
      "[92]: E[R]=139.2100, std(R)=32.8286 | lr=0.0456\n",
      "[93]: E[R]=113.1809, std(R)=53.4646 | lr=0.0455\n",
      "[94]: E[R]=54.9438, std(R)=127.4262 | lr=0.0455\n",
      "[95]: E[R]=62.3819, std(R)=92.7988 | lr=0.0454\n",
      "[96]: E[R]=24.7045, std(R)=131.2812 | lr=0.0454\n",
      "[97]: E[R]=117.7529, std(R)=39.3726 | lr=0.0453\n",
      "[98]: E[R]=151.9786, std(R)=18.2969 | lr=0.0453\n",
      "[99]: E[R]=111.4949, std(R)=100.1172 | lr=0.0452\n"
     ]
    }
   ],
   "source": [
    "es = ESSolver(nn, env, verbose=1)\n",
    "weights = es.solve(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.set_weights(weights, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode end after 1694 iterations with reward = 191.30642198846988 and done status True\n"
     ]
    }
   ],
   "source": [
    "from viz import render_env\n",
    "render_env(nn, env, max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pcl\n",
    "\n",
    "with open(\"more_trained.pcl\", 'wb') as fp:\n",
    "    pcl.dump(weights, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
